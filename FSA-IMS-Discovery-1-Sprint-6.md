# D1:S6 (19/08/19 - 30/08/19)

**Tl;dr**: 41 users met | Needs documented | Recommendations to prototype: buy vs. congifure options for a new core system, and key data flows in, during and out of the service | Plans underway to move into Alpha | Show & tell: [Slides](/iru-discovery-final_presentation-29th_august.pdf) & [Video](https://vimeo.com/356911443)

## This week (...and the one before)
We had a bit of a hiatus last week as most of the team were off on holiday so we pushed the end of the discovery activity into this week (hence the 2 week sprint). As you'd expect, most of the effort has been getting the final write-up of all the consolidated research and analysis finished. We presented back the full set of findings on Tueasday to the core project team and then our final Show & Tell on Thursday to the wider audience / users.

The final cut of the needs for the service are, in priority order:
1. A **single source of truth** for information about incidents and outbreaks
2. **Automatic audit trail** for service providers to effectively evaluate an incident
3. Ability to **search incident data** for relevant information
4. **Regular collaboration** between all parties involved in an incident
5. Consistent and secure method of **sharing intelligence** about incidents
6. Ability to quickly **report on metrics**
7. **Automated population** of templated documents
8. Proactive reduction of incidents using **analysis of data** on incidents
9. Cross-service **visibility of resource** capacity

These are the needs we need to test against during the next Alpha phase. The key themes remain that the existing technology can’t flex to meet modern standards and data can’t flow through the service automatically. This is underpinned by Memex being unable to  adapt to current user needs and lack of web-standard API integrations.

For our recommendations of the core system, we've considered: do nothing (stick with Memex), buy an off-the-shelf product, configure a generic case management platform, or built the software from scratch (or with open source components). Concluding that the best options for the agency to explore in Alpha will be **buy vs. configure**.

And finally, **Kudos** goes out this week to everyone at the FSA who's been involved in this project. So many people to name but the core discovery team, IRU team members, DDAT community, service users, service providers, and the wider FSA teams have all been **fantastic** and we coulnd't have done it without them. Special thanks to Philip for his amazingly kind and complementary words at the start and end of our final Show & Tell. 

## Moving forward
So that's the end of the Discovery (yay!) but what's next? Over the next couple weeks, we'll be:
- Tidying up some of the write-up and sign-off of the final report 
- Completing a Service Blueprint validation group exercise
- Conducting a full Discovery retrospective with the wider DDAT community
- Conducting an assessment of Discovery process with DDAT and some independent assessors from Hackney Council
- Planning for Alpha...

Our current thinking for the Alpha is that we'll be doing a _bake off_ between buy (**Clue**) and configure (**Microsoft Dynamics 365**). We'll be prototyping these solutions (NB: No technology decision is being made at this stage!) against the user needs identified above. Additionally, as data flows (or lack of) is such a key theme for this service, we'll be throwing the following some data integration scenarios in as well. For example, automating the input of the digital service submissions, integrating to the mail exchange (for more effective collaboration) and plugging into Power BI (an existing platform for the FSA) to get data analytics / visualisations.  

This has been a fantastic first Discovery to carry out with the FSA. We're all looking forward to the retro on Wednesday next week to see what learning we can take from this one and continue to deliver top notch [disco's](https://www.youtube.com/watch?v=37wXKoe4L0M) for the agency.